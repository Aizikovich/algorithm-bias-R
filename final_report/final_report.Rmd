---
title: "Final Report"
author: "Team Y"
date: "6/17/2022"
output: html_document
---

```{r load-packages, include = FALSE}
library(knitr)
library(tidyverse)
library(broom)
library(htmltools)
library(dplyr)
library("ggalluvial")
library("gridExtra") 
library(tidymodels)
library(schrute)
library(lubridate)
```

```{r}
# opts_chunk$set(echo=FALSE) # hide source code in the document
path <- setwd("..")
df <- read.csv(
  "data\\data_no_red.csv")

df <- df[,c("comment_id", "annotator_id", "sentiment", "respect", "insult", 
"humiliate", "dehumanize", "violence", "genocide", "attack_defend", 
"hatespeech", "hate_speech_score", "std_err", "target_race", "target_religion", "target_gender", "target_sexuality", 
"annotator_gender", "annotator_educ", "annotator_income", "annotator_ideology", 
"annotator_age", "annotator_race", "annotator_religion", "annotator_sexuality"
)]
```
# section 1 - Intro

```{r}

target_race_me <- df %>% filter(!(hatespeech==1) & annotator_race == "white")
target_race_me <- within(target_race_me, hatespeech[hatespeech == 2] <- 1)

set.seed(1122)

df_model <- target_race_me
df_model <- subset(target_race_me, select = -c(annotator_race, comment_id, annotator_id ))


df_split <- initial_split(df_model)

train <- training(df_split)
test <- testing(df_split)

model <- glm(hatespeech ~ target_race+target_religion+target_gender+target_sexuality+annotator_age, data = train)

summary(model)
```

```{r}
library(caret)

x <- predict(model, newdata = test, type = "response")
xx <- ifelse(x < 0.5, 0, 1)

xxx <- data.frame(Predicted = xx, Actual = test$hatespeech)
xxx$Predicted <- as.factor(xxx$Predicted)

xxx$Actual <- as.factor(xxx$Actual)

caret::confusionMatrix(xxx$Predicted, xxx$Actual)

```

#General
```{r}
target_race_me <- df %>% filter(!(hatespeech==1))
target_race_me <- within(target_race_me, hatespeech[hatespeech == 2] <- 1)

set.seed(1122)

df_model <- target_race_me
df_model <- subset(target_race_me, select = -c(annotator_educ, comment_id, annotator_id, hate_speech_score,sentiment,respect,insult,humiliate,dehumanize,violence,genocide,attack_defend ))


df_split <- initial_split(df_model)

train <- training(df_split)
test <- testing(df_split)

model <- glm(hatespeech ~ target_race+target_religion+target_gender+target_sexuality+annotator_age, data = train)
summary(model)


print("General")
x <- predict(model, newdata = test, type = "response")
xx <- ifelse(x < 0.5, 0, 1)

xxx <- data.frame(Predicted = xx, Actual = test$hatespeech)
xxx$Predicted <- as.factor(xxx$Predicted)

xxx$Actual <- as.factor(xxx$Actual)

caret::confusionMatrix(xxx$Predicted, xxx$Actual)

```
# muslim
```{r}

target_race_me <- df %>% filter(!(hatespeech==1) & annotator_religion == "muslim")
target_race_me <- within(target_race_me, hatespeech[hatespeech == 2] <- 1)

set.seed(1122)

df_model <- target_race_me
df_model <- subset(target_race_me, select = -c(annotator_race, comment_id, annotator_id ))


df_split <- initial_split(df_model)

train <- training(df_split)
test <- testing(df_split)

model <- glm(hatespeech ~ target_race+target_religion+target_gender+target_sexuality+annotator_age, data = train)

summary(model)

x <- predict(model, newdata = test, type = "response")
xx <- ifelse(x < 0.5, 0, 1)

xxx <- data.frame(Predicted = xx, Actual = test$hatespeech)
xxx$Predicted <- as.factor(xxx$Predicted)

xxx$Actual <- as.factor(xxx$Actual)

caret::confusionMatrix(xxx$Predicted, xxx$Actual)
```
# ATU
```{r}
target_race_me <- df %>% filter(!(hatespeech==1) & target_religion == "atheist")
target_race_me <- within(target_race_me, hatespeech[hatespeech == 2] <- 1)

set.seed(1122)

df_model <- target_race_me
df_model <- subset(target_race_me, select = -c(target_religion, comment_id, annotator_id ))


df_split <- initial_split(df_model)

train <- training(df_split)
test <- testing(df_split)

model <- glm(hatespeech ~ target_race+target_gender+target_sexuality+annotator_age, data = train)

summary(model)

x <- predict(model, newdata = test, type = "response")
xx <- ifelse(x < 0.5, 0, 1)

xxx <- data.frame(Predicted = xx, Actual = test$hatespeech)
xxx$Predicted <- as.factor(xxx$Predicted)

xxx$Actual <- as.factor(xxx$Actual)

caret::confusionMatrix(xxx$Predicted, xxx$Actual)

```

# professional_degree

```{r}


target_race_me <- df %>% filter(!(hatespeech==1) & annotator_educ == "professional_degree")
target_race_me <- within(target_race_me, hatespeech[hatespeech == 2] <- 1)

set.seed(1126)

df_model <- target_race_me
df_model <- subset(target_race_me, select = -c(annotator_educ, comment_id, annotator_id, hate_speech_score,sentiment,respect,insult,humiliate,dehumanize,violence,genocide,attack_defend ))


df_split <- initial_split(df_model)

train <- training(df_split)
test <- testing(df_split)

model <- glm(hatespeech ~ ., data = train)

summary(model)

x <- predict(model, newdata = test, type = "response")
xx <- ifelse(x < 0.5, 0, 1)

xxx <- data.frame(Predicted = xx, Actual = test$hatespeech)
xxx$Predicted <- as.factor(xxx$Predicted)

xxx$Actual <- as.factor(xxx$Actual)

caret::confusionMatrix(xxx$Predicted, xxx$Actual)

```

# plot confusionMatrix
         Reference
Prediction  0  1
         0 88 14
         1  0  0
```{r}

Prediction <- factor(c(0, 0, 1, 1))
Reference <- factor(c(0, 1, 0, 1))

g_i <- c(17249, 6778, 2912, 4702)
general <- c(17249/sum(g_i), 6778/sum(g_i), 2912/sum(g_i), 4702/sum(g_i))

m_i <- c(131, 40, 20, 27)
muslim <- c(131/sum(m_i), 40/sum(m_i), 20/sum(m_i), 27/sum(m_i))

a_i <- c(88,14,0,0)
ath <- c(88/sum(a_i), 14/sum(a_i), 0/sum(a_i), 0/sum(a_i))



g_df <- data.frame(Reference, Prediction, general)
m_df <- data.frame(Reference, Prediction, muslim)
a_df <- data.frame(Reference, Prediction, ath)

p1<-ggplot(data =  g_df, mapping = aes(x = Reference, y = Prediction)) +
      geom_tile(aes(fill = general), colour = "white") +
      geom_text(aes(label = sprintf("%0.3f", general)), vjust = 1, size=10) +
      scale_fill_gradient(low = "blue", high = "green") +
      labs(title = 'Confusion Matrix Ratio - General model', subtitle = " Accuracy : 0.6938 ")+
      theme_bw() +  theme(legend.position = "none",
                           plot.title = element_text(hjust = 0.5),
                           plot.subtitle = element_text(hjust = 0.5))

p2<-ggplot(data =  g_df, mapping = aes(x = Reference, y = Prediction)) +
      geom_tile(aes(fill = muslim), colour = "white") +
      geom_text(aes(label = sprintf("%0.3f", muslim)), vjust = 1, size=10) +
      scale_fill_gradient(low = "blue", high = "green") +
      labs(title = 'Confusion Matrix Ratio - Muslim Annotators', subtitle = "Accuracy : 0.7248 ")+
      theme_bw() +  theme(legend.position = "none",
                           plot.title = element_text(hjust = 0.5),
                           plot.subtitle = element_text(hjust = 0.5))

p3 <- ggplot(data =  a_df, mapping = aes(x = Reference, y = Prediction)) +
        geom_tile(aes(fill = ath), colour = "white") +
        geom_text(aes(label = sprintf("%0.3f", ath)), vjust = 1, size=10) +
        scale_fill_gradient(low = "blue", high = "green") +
        labs(title = 'Confusion Matrix Ratio - Atheist Annotators', subtitle = " Accuracy : 0.8627 ")+
        theme_bw() + theme(legend.position = "none",
                           plot.title = element_text(hjust = 0.5, size= 20),
                           plot.subtitle = element_text(hjust = 0.5))



```

```{r}
p1
p2
p3
```

